{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Никитин Дмитрий 4217\n",
    "## Вариант №3\n",
    "\"Классификация текстов (IMDb Reviews)\"\n",
    "Описание задачи:\n",
    "Используем датасет IMDb Reviews, который состоит из текстовых отзывов о фильмах, помеченных как положительные (positive) или отрицательные (negative). Нужно обучить нейронную сеть для классификации текстов на основе этих данных.\n",
    "Шаги работы:\n",
    "1. *Загрузка данных:* датасет IMDb Reviews доступен через Keras и на Kaggle.\n",
    "2. *Предобработка данных:* тексты в датасете представлены в виде индексов слов в словаре. Надо преобразовать их обратно в текстовый формат для дальнейшей обработки. Нужно преобразовать индексы в массивы с использованием pad_sequences, чтобы тексты были одинаковой длины\n",
    "3. *Обучение модели:* создать нейронную сеть для классификации текста на положительный или отрицательный отзыв.\n",
    "4. *Тестирование:* протестировать модель на тестовых данных. Оценить точность модели на тестовой выборке."
   ],
   "metadata": {
    "id": "AlT6stOT1fcD"
   },
   "id": "386579a39c55b19"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Сначала был проведён просмотр датасета."
   ],
   "metadata": {
    "id": "jbTI6dSa7iRr"
   },
   "id": "7850144586b596f7"
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "Xbe-sHrJ1Y4l",
    "outputId": "e58b7414-5d17-41e2-c284-ecccc576dd3d",
    "ExecuteTime": {
     "end_time": "2025-03-02T21:13:49.686779Z",
     "start_time": "2025-03-02T21:13:48.932782Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataset = pd.read_csv(\"data/IMDB Dataset.csv\")\n",
    "\n",
    "dataset.head(10)"
   ],
   "id": "9ed6397868291b17",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
       "5  Probably my all-time favorite movie, a story o...  positive\n",
       "6  I sure would like to see a resurrection of a u...  positive\n",
       "7  This show was an amazing, fresh & innovative i...  negative\n",
       "8  Encouraged by the positive comments about this...  negative\n",
       "9  If you like original gut wrenching laughter yo...  positive"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Probably my all-time favorite movie, a story o...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I sure would like to see a resurrection of a u...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>This show was an amazing, fresh &amp; innovative i...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Encouraged by the positive comments about this...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>If you like original gut wrenching laughter yo...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "markdown",
   "source": [
    "Далее был очищен текст (удалены лишние символы, приведён к нижнему регистру)."
   ],
   "metadata": {
    "id": "v8RfdQJ28Bg6"
   },
   "id": "663ac16f730bd066"
  },
  {
   "cell_type": "code",
   "source": [
    "import re\n",
    "\n",
    "# Очистка текста\n",
    "def clean_text(text: str) -> str:\n",
    "  # Удаление тегов HTML\n",
    "  text: str = re.sub(r'<.*?>', '', text)\n",
    "\n",
    "  # Удаление символов, не являющихся буквой, цифрой, нижним подчёркиванием или\n",
    "  # пробелом\n",
    "  text: str = re.sub(r'[^\\w\\s]', '', text)\n",
    "\n",
    "  text: str = text.lower()\n",
    "\n",
    "  return text\n",
    "\n",
    "# Превращение positive и negative оценок в 1 и 0 соответственно\n",
    "def sentiment_to_number(sentiment: str) -> int:\n",
    "  if sentiment == \"positive\":\n",
    "    return 1\n",
    "  else:\n",
    "    return 0\n",
    "\n",
    "dataset['sentiment'] = dataset['sentiment'].apply(sentiment_to_number)\n",
    "dataset['review'] = dataset['review'].apply(clean_text)\n",
    "\n",
    "dataset\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "b37MEauF8UEU",
    "outputId": "4415a2da-7b71-4350-a5ca-7a80e953b5b7",
    "ExecuteTime": {
     "end_time": "2025-03-02T21:13:51.632792Z",
     "start_time": "2025-03-02T21:13:49.736194Z"
    }
   },
   "id": "47bbfcc5d91d0c58",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                                  review  sentiment\n",
       "0      one of the other reviewers has mentioned that ...          1\n",
       "1      a wonderful little production the filming tech...          1\n",
       "2      i thought this was a wonderful way to spend ti...          1\n",
       "3      basically theres a family where a little boy j...          0\n",
       "4      petter matteis love in the time of money is a ...          1\n",
       "...                                                  ...        ...\n",
       "49995  i thought this movie did a down right good job...          1\n",
       "49996  bad plot bad dialogue bad acting idiotic direc...          0\n",
       "49997  i am a catholic taught in parochial elementary...          0\n",
       "49998  im going to have to disagree with the previous...          0\n",
       "49999  no one expects the star trek movies to be high...          0\n",
       "\n",
       "[50000 rows x 2 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one of the other reviewers has mentioned that ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a wonderful little production the filming tech...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i thought this was a wonderful way to spend ti...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basically theres a family where a little boy j...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter matteis love in the time of money is a ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>i thought this movie did a down right good job...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>bad plot bad dialogue bad acting idiotic direc...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>i am a catholic taught in parochial elementary...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>im going to have to disagree with the previous...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>no one expects the star trek movies to be high...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 2 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "markdown",
   "source": [
    "Далее текст был преобразован в числовой формат или же токенизирован. Токенизация — это процесс преобразования текста в последовательность чисел (токенов), которые могут быть обработаны нейронной сетью. В данном случае используется Tokenizer из библиотеки TensorFlow/Keras, который создаёт словарь из наиболее часто встречающихся слов и присваивает каждому слову уникальный индекс. Слова, не вошедшие в словарь, заменяются на специальный токен <OOV> (Out Of Vocabulary). После этого тексты преобразуются в последовательности чисел, а затем дополняются нулями или обрезаются до одинаковой длины с помощью функции pad_sequences, чтобы все входные данные имели единый размер для обработки моделью."
   ],
   "metadata": {
    "id": "gJdQIqJ-BLGP"
   },
   "id": "168df67b58aed001"
  },
  {
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "vocab_size = 10000 # Размер словаря\n",
    "max_length = 200 # Максимальный размер последовательности\n",
    "\n",
    "# Создание токенизатора - редкоиспользуемые слова были помечены как <00V>\n",
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=vocab_size, oov_token=\"<00V>\")\n",
    "# Обучение токенизатора\n",
    "tokenizer.fit_on_texts(dataset['review'])\n",
    "\n",
    "# Преобразование текста в последовательности чисел\n",
    "sequences = tokenizer.texts_to_sequences(dataset['review'])\n",
    "\n",
    "# Обрезанные и продлённые последовательности одной длины\n",
    "padded_sequences = tf.keras.preprocessing.sequence.pad_sequences(sequences, maxlen=max_length, padding='post', truncating='post')"
   ],
   "metadata": {
    "id": "TD1Vtf6DBTMy",
    "ExecuteTime": {
     "end_time": "2025-03-02T21:14:09.070374Z",
     "start_time": "2025-03-02T21:13:51.711474Z"
    }
   },
   "id": "d63ad45400427426",
   "outputs": [],
   "execution_count": 18
  },
  {
   "cell_type": "markdown",
   "source": [
    "Далее данные были разделены на обучающую и тестовую выборки."
   ],
   "metadata": {
    "id": "jhhB2NFEElY1"
   },
   "id": "f68f1798fff9a152"
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 80% датасета используется для тренировки, 20% - для тестирования\n",
    "X_train, X_test, y_train, y_test = train_test_split(padded_sequences, dataset['sentiment'], test_size=0.2, random_state=0)"
   ],
   "metadata": {
    "id": "WW7y354JHSRf",
    "ExecuteTime": {
     "end_time": "2025-03-02T21:14:09.149091Z",
     "start_time": "2025-03-02T21:14:09.118328Z"
    }
   },
   "id": "207f2e724391bec",
   "outputs": [],
   "execution_count": 19
  },
  {
   "cell_type": "markdown",
   "source": [
    "Создание нейронной сети начинается с определения её архитектуры с помощью tf.keras.Sequential, которая позволяет последовательно добавлять слои. Первый слой — Embedding, преобразует целочисленные индексы слов в плотные векторы фиксированной размерности (в данном случае 64), что позволяет модели работать с семантическим значением слов. Далее идёт слой Flatten, который \"выравнивает\" многомерные данные в одномерный вектор, подготавливая их для полносвязных слоёв. Затем добавляется полносвязный слой Dense с 64 нейронами и функцией активации ReLU f(x) = max(0, x), который помогает модели выявлять сложные зависимости в данных. Выходной слой Dense с одним нейроном и функцией активации sigmoid, преобразующей выход в вероятность: f(x) = 1 / (1 + exp(-x)), используется для бинарной классификации, выдавая вероятность принадлежности к классу 1 (например, положительный отзыв). После создания архитектуры модель компилируется с использованием оптимизатора Adam, функции потерь binary_crossentropy (для бинарной классификации) и метрики accuracy для оценки точности. Метод model.summary() выводит структуру модели, включая информацию о каждом слое, форме выходных данных и количестве обучаемых параметров."
   ],
   "metadata": {
    "id": "A0fMW8yeIflk"
   },
   "id": "2427ac215312823e"
  },
  {
   "cell_type": "code",
   "source": [
    "# Создание модели\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=64, input_length=max_length, input_shape=(max_length,)), # Слой Embedding\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid') # Выходной слой для бинарной классификации\n",
    "])\n",
    "\n",
    "# Компиляция модели\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "# Вывод структуры модели\n",
    "print(model.summary())"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 368
    },
    "id": "OdBHriR_Ik07",
    "outputId": "f857438a-3e36-440d-be4d-deb8b561c06a",
    "ExecuteTime": {
     "end_time": "2025-03-02T21:14:09.230538Z",
     "start_time": "2025-03-02T21:14:09.164672Z"
    }
   },
   "id": "d818edb91ff887af",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\johnworker\\.conda\\envs\\Lab1\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n",
      "C:\\Users\\johnworker\\.conda\\envs\\Lab1\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1mModel: \"sequential_2\"\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)                   \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m      Param #\u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_2 (\u001B[38;5;33mEmbedding\u001B[0m)         │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m200\u001B[0m, \u001B[38;5;34m64\u001B[0m)        │       \u001B[38;5;34m640,000\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_2 (\u001B[38;5;33mFlatten\u001B[0m)             │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m12800\u001B[0m)          │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001B[38;5;33mDense\u001B[0m)                 │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m64\u001B[0m)             │       \u001B[38;5;34m819,264\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001B[38;5;33mDense\u001B[0m)                 │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m1\u001B[0m)              │            \u001B[38;5;34m65\u001B[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">640,000</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12800</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │       <span style=\"color: #00af00; text-decoration-color: #00af00\">819,264</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m1,459,329\u001B[0m (5.57 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,459,329</span> (5.57 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m1,459,329\u001B[0m (5.57 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,459,329</span> (5.57 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m0\u001B[0m (0.00 B)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "cell_type": "markdown",
   "source": [
    "Вывод говорит о том, что модель была создана верно. Отображены все 4 слоя, заданные в коде.\n",
    "\n",
    "Слой embedding преобразует целочисленные индексы слов в плотные векторы фиксированной размерности. В данном случае каждое слово является вектором из 64 чисел.\n",
    "\n",
    "Слой flatten преобразует её в вектор длины 200 * 64 = 12,800.\n",
    "\n",
    "Верхний dense - полносвязный слой, который обучается на данных. Каждый нейрон в этом слое принимает входные данные от всех элементов предыдущего слоя и применяет к ним веса и смещения.\n",
    "\n",
    "Вход: вектор длины 12,800.\n",
    "\n",
    "Выход: вектор длины 64.\n",
    "\n",
    "Функция активации relu (Rectified Linear Unit) добавляет нелинейность: f(x) = max(0, x).\n",
    "\n",
    "Нижний dense - выходной слой для бинарной классификации.\n",
    "\n",
    "Выдаёт вероятность принадлежности к классу 1.\n",
    "\n",
    "Вход: вектор длины 64.\n",
    "\n",
    "Выход: одно число (от 0 до 1).\n",
    "\n",
    "Функция активации sigmoid преобразует выход в вероятность: f(x) = 1 / (1 + exp(-x))."
   ],
   "metadata": {
    "id": "PIl-a6NGOScf"
   },
   "id": "87cc70ffeb400df2"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Далее было проведено обучение модели на данных для обучения."
   ],
   "metadata": {
    "id": "tBZ9L3FdgeGU"
   },
   "id": "c70388aaf026af0f"
  },
  {
   "cell_type": "code",
   "source": [
    "# Обучение модели\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=5,\n",
    "    batch_size=512,\n",
    "    validation_data=(X_test, y_test)\n",
    ")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6UqTOhi-NOIv",
    "outputId": "417c2d7d-38bc-42f6-e404-31c978d31840",
    "ExecuteTime": {
     "end_time": "2025-03-02T21:14:19.960940Z",
     "start_time": "2025-03-02T21:14:09.314923Z"
    }
   },
   "id": "8daa486bbf0f1c82",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 25ms/step - accuracy: 0.6180 - loss: 0.6243 - val_accuracy: 0.8451 - val_loss: 0.3564\n",
      "Epoch 2/5\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 24ms/step - accuracy: 0.8945 - loss: 0.2622 - val_accuracy: 0.8584 - val_loss: 0.3359\n",
      "Epoch 3/5\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 24ms/step - accuracy: 0.9624 - loss: 0.1276 - val_accuracy: 0.8445 - val_loss: 0.3781\n",
      "Epoch 4/5\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 23ms/step - accuracy: 0.9950 - loss: 0.0386 - val_accuracy: 0.8492 - val_loss: 0.4179\n",
      "Epoch 5/5\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 23ms/step - accuracy: 0.9986 - loss: 0.0154 - val_accuracy: 0.8485 - val_loss: 0.4535\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "cell_type": "markdown",
   "source": [
    "Во время выполнения команды model.fit происходит процесс обучения нейронной сети. Модель последовательно обрабатывает обучающие данные (X_train и y_train) в течение 5 эпох (полных проходов по всему набору данных). На каждом шаге данные разбиваются на батчи размером 512 примеров, что позволяет эффективно использовать память и ускорить обучение. В процессе обучения модель выполняет прямое распространение (forward pass), вычисляет ошибку (loss) с помощью функции потерь binary_crossentropy, а затем обновляет свои веса с помощью оптимизатора Adam, минимизируя ошибку. После каждой эпохи модель оценивается на валидационных данных (X_test и y_test), что позволяет отслеживать её обобщающую способность и избегать переобучения. Результаты обучения (ошибка и точность на тренировочных и валидационных данных) сохраняются в объекте history, который можно использовать для анализа и визуализации процесса обучения. Чем больше батчей, тем быстрее процесс обучения, но требуется больше памяти."
   ],
   "metadata": {
    "id": "Fr8M1s7ZWLNM"
   },
   "id": "d3fe5298ca5ec15e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Далее была проведена оценка модели."
   ],
   "metadata": {
    "id": "r_l9e-GvhfwA"
   },
   "id": "46032b89b6d623e1"
  },
  {
   "cell_type": "code",
   "source": [
    "# Оценка модели\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Точность на тестовых данных: {accuracy:.2f}\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KV2_ie9uNPp-",
    "outputId": "0ecc8387-2cfd-490d-9323-312ea2996fe6",
    "ExecuteTime": {
     "end_time": "2025-03-02T21:14:20.704079Z",
     "start_time": "2025-03-02T21:14:19.966019Z"
    }
   },
   "id": "19b60626ac939f5e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m313/313\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 2ms/step - accuracy: 0.8509 - loss: 0.4570\n",
      "Точность на тестовых данных: 0.85\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "cell_type": "markdown",
   "source": [
    "Команда model.evaluate используется для оценки обученной модели на тестовых данных (X_test и y_test). В процессе выполнения модель обрабатывает тестовые данные, вычисляет значение функции потерь (loss) и точность (accuracy), которые показывают, насколько хорошо модель справляется с предсказаниями на новых, ранее не виденных данных. В данном случае выводится точность модели на тестовых данных, округлённая до двух знаков после запятой. Например, если точность составляет 0.85, это означает, что модель правильно классифицировала 85% тестовых примеров. Этот этап позволяет оценить качество модели и её способность обобщать знания на реальных данных."
   ],
   "metadata": {
    "id": "KOiQfhsiiKts"
   },
   "id": "beaff84b5ab36046"
  }
 ]
}
